""" Plot experiments from timeseries csv files generated by
    the `utils/build_timeseries_metrics_df.py` script.
"""

import os
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from itertools import groupby

sns.set_style("whitegrid")

def plot_timeseries_dfs(**dfs):
    # add strategy identifier column to all dataframes
    for key, df in dfs.items():
        # make sure the data is valid
        if (len(df.index) == 0) or ('_step' != df.index.name):
            dfs[key] = None
            continue
        # melt and add strategy column
        df = pd.melt(df, ignore_index=False)
        df.dropna(inplace=True, subset="value")
        df['strategy'] = key
        # write back into to dict
        dfs[key] = df

    # filter out invalids
    dfs = [df for df in dfs.values() if df is not None]
    # check for any valid data
    if len(dfs) == 0:
        return None

    # concatenate dataframes
    df = pd.concat(dfs)
    xs = df.index.unique()

    # plot
    ax = sns.lineplot(
        data=df,
        x="_step",
        y="value",
        hue="strategy",
        legend="brief",
    )
    # log-scale
    ax.set(xscale='log')
    ax.set(xticks=xs, xticklabels=[xs.min()] + [""] * (len(xs)-2) + [xs.max()])
    # return axes
    return ax

if __name__ == "__main__":

    project_dir = "./al_results/active-final-q25-b1000"
    strategies = {
        "random": "random",
        "alps": "alps",
        "egl-sampling": "egl",
        "least-confidence": "lc",
        "prediction-entropy": "pe",
        "entropy-over-max": "eom",
        "entropy-over-max-ignore": "eom-ignore",
    }

    assert os.path.isdir(project_dir), "Project directory not found"
    # loop over all experiments
    for experiment_name in os.listdir(project_dir):
        experiment_dir = os.path.join(project_dir, experiment_name)
        assert os.path.isdir(experiment_dir)
        # get all timeseries files of the experiment
        fnames = os.listdir(experiment_dir)
        fnames = [fname for fname in fnames if fname.endswith(".csv")]
        # group by metrics
        key = lambda fname: fname[:-4].split('.', 1)[1]
        grouped_fnames = groupby(sorted(fnames, key=key), key=key)

        print("Plotting runs for <%s>..." % experiment_name)
        # create plot directory
        os.makedirs("al_plots/%s" % experiment_name, exist_ok=True)
        # iterate over present metrics
        for metric, fnames in grouped_fnames:
            fnames = list(fnames)
            # infer strategy identifier from filename
            keys = [fname.rsplit('-', 1)[0] for fname in fnames]
            keys = [strategies.get(strat, None) for strat in keys]
            # filter out unwanted strategies
            fnames = [fname for fname, key in zip(fnames, keys) if key is not None]
            keys = [key for key in keys if key is not None]
            # load timeseries dataframes
            fpaths = [os.path.join(experiment_dir, fname) for fname in fnames]
            dfs = [pd.read_csv(fpath, index_col=0) for fpath in fpaths]
            # plot
            ax = plot_timeseries_dfs(**dict(zip(keys, dfs)))
            ax.set(
                title=experiment_name,
                xlabel="Train Samples",
                ylabel=metric.replace('.', '/')
            )
            if ax is not None:
                # save and close
                ax.get_figure().savefig("al_plots/%s/%s.png" % (experiment_name, metric))
                plt.close('all')
